{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e371127",
   "metadata": {},
   "source": [
    "### 0 使用CPU进行模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab31ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cbd55a3",
   "metadata": {},
   "source": [
    "### 1 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84afdd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 (60000, 28, 28) (60000,)\n",
      "测试集 (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(train_images, train_labels), (test_images, test_labels) =mnist.load_data(\"mnist.npz\")\n",
    "print('训练集',train_images.shape,train_labels.shape)\n",
    "print('测试集',test_images.shape,test_labels.shape)\n",
    "\n",
    "img_row,img_col,channel = 28,28,1 # 图像的 高(行row),宽(列col),通道 = 28,28,1\n",
    "\n",
    "#将数据维度进行处理\n",
    "train_images = train_images.reshape(train_images.shape[0],img_row,img_col,channel) # 1,28,28,1\n",
    "test_images = test_images.reshape(test_images.shape[0],img_row,img_col,channel) # 1,28,28,1\n",
    "\n",
    "train_images = train_images.astype(\"float32\") \n",
    "test_images = test_images.astype(\"float32\")\n",
    "\n",
    "## 进行归一化处理\n",
    "train_images  /= 255    \n",
    "test_images /= 255  # test_images = test_images/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1c75ed1",
   "metadata": {},
   "source": [
    "### 2 构建LeNet-5模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7b7c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "3000/3000 [==============================] - 15s 5ms/step - loss: 0.1531 - accuracy: 0.9532 - val_loss: 0.0574 - val_accuracy: 0.9805\n",
      "Epoch 2/5\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.0539 - accuracy: 0.9832 - val_loss: 0.0380 - val_accuracy: 0.9874\n",
      "Epoch 3/5\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.0364 - accuracy: 0.9884 - val_loss: 0.0393 - val_accuracy: 0.9859\n",
      "Epoch 4/5\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0380 - val_accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "3000/3000 [==============================] - 14s 5ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0377 - val_accuracy: 0.9888\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x198b7b8d9d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建模型\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28,28,1)),\n",
    "  keras.layers.Reshape(target_shape=(28,28,1)),\n",
    "  keras.layers.Conv2D(filters=8, kernel_size=(3,3),padding=\"same\",activation=\"relu\",name='conv1'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2,2),name='pool1'),\n",
    "  keras.layers.Conv2D(filters=16, kernel_size=(3,3),padding=\"same\",activation=\"relu\",name='conv2'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2,2),name='pool2'),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(128, activation='relu',name='fc1'),\n",
    "  keras.layers.Dense(10, activation='softmax',name='fc2')\n",
    "])\n",
    "\n",
    "# 编译并训练\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels,epochs=5, batch_size=20, validation_data=(test_images,test_labels))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93870a8b",
   "metadata": {},
   "source": [
    "### 3 保存LeNet-5模型为h5格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4df82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 28, 28, 8)         80        \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 14, 14, 8)         0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 14, 14, 16)        1168      \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 7, 7, 16)          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 128)               100480    \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,018\n",
      "Trainable params: 103,018\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 显示模型信息\n",
    "model.summary()\n",
    "# 保存模型\n",
    "model.save('lenet.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e56edf5",
   "metadata": {},
   "source": [
    "### 4 将h5格式的模型转换为tflite格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29340dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpl4t4i2uh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpl4t4i2uh\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "keras_model = tf.keras.models.load_model('lenet.h5')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "471ded7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_name = \"lenet.tflite\"\n",
    "open(tflite_name, \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51c9056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFLite是一个用于在移动设备和边缘设备上部署机器学习模型的框架。在TFLite中，将模型的权重和偏差量化为8位整数可以显著减少模型的大小，从而提高模型的性能和效率。\n",
    "# 然而，当将模型量化为int8时，偏差的值可能会超过127，这是因为偏差是在训练过程中学习的，并且可能具有比权重更广泛的分布。\n",
    "# 如果将偏差强制限制为小于等于127，可能会导致精度损失或性能下降。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3505f26",
   "metadata": {},
   "source": [
    "### 5 将h5模型量化为int8的tflite模型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c38de9f3",
   "metadata": {},
   "source": [
    "量化策略：DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f743bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpbc60l9jh\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:\\USER_T~1\\tmpbc60l9jh\\assets\n"
     ]
    }
   ],
   "source": [
    "# 加载Keras模型\n",
    "keras_model = tf.keras.models.load_model('lenet.h5')\n",
    "converter_quant = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "converter_quant.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "  ]\n",
    "# set the optimization parameters for TensorFlow Lite conversion\n",
    "converter_quant.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# convert the model to TensorFlow Lite format with float32 activations and int8 weights\n",
    "quanitfied_defult_model = converter_quant.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af3c1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108040"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#保存转换后的模型\n",
    "quanitfied_defult_name = \"lenet_quanitfied.tflite\"\n",
    "open(quanitfied_defult_name, \"wb\").write(quanitfied_defult_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2b59896",
   "metadata": {},
   "source": [
    "### 6 模型验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b145d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(interpreter_path):\n",
    "    #加载模型并分配张量\n",
    "    interpreter = tf.lite.Interpreter(model_path=interpreter_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    #获得输入输出张量.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    index = input_details[0]['index']\n",
    "    shape = input_details[0]['shape']\n",
    "    acc_count = 0\n",
    "    image_count = test_images.shape[0]\n",
    "    for i in range(image_count):\n",
    "        #interpreter.set_tensor(index, test_images[i].reshape(shape).astype(\"float32\"))\n",
    "        interpreter.set_tensor(index, (test_images[i].reshape(shape)*255).astype(\"float32\"))\n",
    "        interpreter.invoke()\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "        label = np.argmax(output_data)\n",
    "        if label == test_labels[i]:\n",
    "            acc_count += 1\n",
    "    print(\"test_images accuracy is {:.2%}\".format(acc_count/(image_count)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144dce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite\n",
      "test_images accuracy is 98.54%\n"
     ]
    }
   ],
   "source": [
    "print('tflite')\n",
    "evaluate_model('lenet.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b502387c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tflite_quanitfied\n",
      "test_images accuracy is 98.58%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('tflite_quanitfied')\n",
    "evaluate_model('lenet_quanitfied.tflite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
